================================================================================
                 BOG OFFERS CHATBOT — PROJECT DOCUMENTATION
================================================================================

პროექტი: Bank of Georgia Offers Chatbot
ენა: Python
მთავარი იდეა: RAG (Retrieval-Augmented Generation) + Taxonomy + Chat UI

ტექნოლოგიები:
- Embeddings: sentence-transformers (default: BAAI/bge-m3)
- Vector DB: Qdrant (Cloud ან local)
- UI: Streamlit
- LLM: OpenAI ან Gemini (optional), ან retrieval-only რეჟიმი

ეს დოკუმენტი აღწერს პროექტს თავიდან ბოლომდე — როგორ იქმნება data (knowledge) base,
როგორ ინახება Qdrant-ში, როგორ ხდება retrieval/რანჟირება, სად ერთვება taxonomy,
და როგორ მუშაობს UI/CLI.

================================================================================
1) სწრაფი გაშვება (Quick Start)
================================================================================

1) Dependencies
   pip install -r requirements.txt

2) შექმენი .env ფაილი (repo root-ში)
   მინიმუმ:
     QDRANT_URL=...
     QDRANT_API_KEY=...
   LLM-ისთვის (არასავალდებულო):
     OPENAI_API_KEY=...
     GEMINI_API_KEY=...

3) ააგე ინდექსი ერთხელ (ან როცა data შეიცვლება)
   python -m rag.build_index

4) გაუშვი UI
   python launch.py
   ან
   streamlit run ui/app.py

================================================================================
2) პროექტის მაღალი დონის არქიტექტურა
================================================================================

Data acquisition (scraper/) → data/raw → data/processed → Index build (rag/build_index.py)
                                                           ↓
                                                         Qdrant

Query-time:
User → Streamlit UI → llm/chatbot.py → rag/retriever.py → Qdrant search → taxonomy normalize
                                                                       ↓
                                                          prompt (llm/prompts.py)
                                                                       ↓
                                                          LLM (optional) → Answer

================================================================================
3) WEB SCRAPER (scraper/)
================================================================================

მიზანი: bog.ge-დან შეთავაზებების შეგროვება.

შედეგად მიიღება:
- data/raw/found_offers.json
- data/raw/cities.json

შემდეგ ხდება enrich/merge და ბოლოს მიიღება:
- data/processed/found_offers.json (ეს არის indexing-ის „source of truth“)

ტაქსონომია ემატება აქ, რაც ცოტათი გაურკვეველ ცვლადებს ან სხვა ატრიბუტებს "თარგმნის". 

სტრუქტურა ცოტა კომპლექსური და ჩახლართული ჩანს, მაგრამ იდეა იყო მოდულარულობა.

================================================================================
4) DATA STRUCTURE (data/)
================================================================================

data/raw/
- found_offers.json    -> პირველადი (raw) შეთავაზებები
- cities.json          -> ქალაქების mapping (მაგ: cityId)

data/processed/
- found_offers.json    -> დამუშავებული შეთავაზებები, indexing-ისთვის მზად
- taxonomy.json        -> taxonomy rules + overrides (benefit normalization)

Offer object-ის ტიპური ველები (short schema):
{
  "brand_name": "...",
  "title": "...",
  "category_desc": "...",
  "description": "...",
  "benef_name": "DISCOUNT" | "CASHBACK" | ...,
  "benef_badge": "%" | "X" | ...,
  "product_code": "SOLO" | ...,
  "segment_type": "ALL" | ...,
  "start_date": "YYYY-MM-DD" | "",
  "end_date": "YYYY-MM-DD" | "",
  "cities": "თბილისი, ბათუმი" | ["თბილისი", ...] | "",
  "details_url": "https://..."
}

================================================================================
5) RAG SYSTEM (rag/) — რა ხდება ტექნიკურად
================================================================================

RAG ფოლდერის მიზანია:
1) შეთავაზებების ტექსტის ემბედინგებად გარდაქმნა
2) Qdrant-ში ვექტორების შენახვა
3) query-time similarity search
4) ჰიბრიდული რანჟირება (vector score + lexical overlap)

5.1 rag/embeddings.py
---------------------
კლასი: EmbeddingGenerator

როლი:
- SentenceTransformer მოდელის ჩატვირთვა
- offer dict → ერთიანი „document text“ (preprocess_offer)
- ტექსტების embeddings გენერაცია (generate_embeddings)

მთავარი ლოგიკა:
- preprocess_offer(): აწყობს compact ტექსტს ქართული ლეიბლებით
  მაგალითად: "ბრენდი: ...\nკატეგორია: ...\nსარგებელი: ..." და ა.შ.
- generate_embeddings(): model.encode(..., normalize_embeddings=True)
  ეს მნიშვნელოვანია COSINE similarity-ისთვის.

5.2 rag/vector_store.py
-----------------------
კლასი: VectorStore

როლი:
- QdrantClient-ის შექმნა (lazy)
- კოლექციის არსებობის შემოწმება/შექმნა
- vectors+payload batch upsert
- similarity search

დეტალები:
- payload აუცილებლად უნდა იყოს JSON-serializable
  ამიტომ გამოიყენება _ensure_serializable_payload() (ტიპების „გასუფთავება“).
- upsert ხდება batch-ებად (default: 64), რომ არ გადაიტვირთოს request.

5.3 rag/retriever.py
--------------------
კლასი: OfferRetriever

როლი:
- query embedding
- Qdrant search top_k შედეგებით
- reranking:
  - lexical overlap გამოთვლა (ქართული+ლათინური ტოკენიზაცია)
  - combined_score = vector_score + lexical_boost * overlap
- query ტიპის გარჩევა:
  - recommendation query: „მირჩიე“, „რეკომენდ...“, „offers“ → უფრო ფართო შედეგები
  - factual question: „ვინ/როდის/სად/?“ → მკაცრი ფილტრი (min_factual_overlap)

შედეგი:
- აბრუნებს უკვე დალაგებულ offers list-ს, სადაც თითო ელემენტს აქვს:
  - score
  - text (indexed doc ტექსტი)
  - metadata (payload-ის დანარჩენი ნაწილი)

5.4 rag/taxonomy.py
-------------------
კლასი: TaxonomyEngine

როლი:
- offer metadata-ში სარგებლის სტანდარტიზაცია, რომ:
  - LLM-ს არ აურიოს % და X / cashback vs discount
  - შეძლოს value/unit ამოღება (მაგ: 20 და "%")

taxonomy.json შეიცავს:
- benefit_types: სტანდარტული ტიპები და ქართული სახელები
- rules: regex-based წესები (priority-ით)
- offer_annotations: კონკრეტული შეთავაზების override (details_url-ზე დაყრდნობით)

როდის ერთვება taxonomy?
- Query-time: retrieval-ის შემდეგ, სანამ prompt აიწყობა.
  ანუ: retriever.retrieve() → taxonomy.normalize_offer() → prompt.format_offers()

Output:
- NormalizedBenefit: benefit_type_id + benefit_label_ka + value + value_unit + rule_id + source
  ეს ველები ემატება offer.metadata-ში, რათა prompt-ში ყოველთვის ერთნაირად გამოჩნდეს.

5.5 rag/build_index.py
----------------------
როლი: indexing pipeline (ერთჯერადი/რეგულარული job)

სთეფები:
1) data/processed/found_offers.json ჩატვირთვა
2) EmbeddingGenerator ინიციალიზაცია
3) VectorStore ინიციალიზაცია
4) Qdrant reachable check
5) თითო offer-ზე:
   - preprocess_offer() → documents
   - metadata (payload) მომზადება
6) generate_embeddings(documents)
7) create_collection(vector_size)
8) add_documents(documents, embeddings, metadata)

გაშვება:
  python -m rag.build_index

5.6 rag/query_index.py
----------------------
როლი: smoke test / debugging

გაშვება:
  python -m rag.query_index "query ტექსტი"

გამოაქვს:
- top შედეგები (score + basic fields) რათა დაადასტურო რომ retrieval მუშაობს. არანაირი დიდი
მნიშვნელობა არ აქვს უბრალოდ უფასო ტესტია.

================================================================================
6) LLM INTEGRATION (llm/)
================================================================================

6.1 llm/prompts.py
------------------
კლასი: PromptTemplates

როლი:
- SYSTEM_PROMPT: ასისტენტის როლი და პასუხის წესები
- USER_QUERY_TEMPLATE: query + retrieved offers + ინსტრუქციები
- format_offers(): retrieved offers → ერთიანი ტექსტი (evidence block)
- create_user_message(): საბოლოო user message

შენიშვნა follow-up-ზე:
- prompt შეიცავს ინსტრუქციას, რომ თუ კითხვა გაგრძელებაა („ეს“, „ამის შესახებ“, „კიდევ“),
  უნდა გამოიყენოს იგივე კონტექსტი და არ „გადახტეს“ სხვა შეთავაზებებზე.

6.2 llm/chatbot.py
------------------
კლასი: BOGChatbot

როლი:
- provider/model არჩევა (.env/config)
- retrieval pipeline გაშვება
- taxonomy normalization შედეგებზე
- prompt assembly (system + short history + user prompt)
- LLM call (OpenAI ან Gemini), ან fallback retrieval-only output

Follow-up behavior (ძალიან პრაქტიკული ნაწილი):
- ბოტი ინახავს ბოლო retrieval results-ს
- თუ ახალი კითხვა მოკლე/პრონაუნიანი გაგრძელებაა, შეუძლია:
  - retrieval query ცოტათი გააფართოვოს წინა query-ით
  - თუ retrieval ვერ პოულობს შედეგებს, გამოიყენოს წინა offers
  - ან merge გააკეთოს, რომ კონტექსტი არ დაიკარგოს

CLI:
- One-shot: python -m llm.chatbot "..."
- Interactive: python -m llm.chatbot
- No-LLM: python -m llm.chatbot --no-llm "..."

================================================================================
7) UI (ui/)
================================================================================

ui/app.py (Streamlit)

როლი:
- Chat UI: st.chat_input + st.chat_message
- Session state: st.session_state.messages
- Bot caching: @st.cache_resource (ბოტის ერთჯერადი ინიციალიზაცია)
- Sidebar:
  - „ახალი საუბარი“ ღილაკი (UI history + bot memory reset)
- Error handling:
  - human-friendly ტექსტი + ლოგირება

გაშვება:
  streamlit run ui/app.py
  ან
  python launch.py

================================================================================
8) CONFIGURATION (config.py + .env)
================================================================================

პროექტი იყენებს .env ცვლადებს.

მინიმალური .env (Qdrant-ისთვის):
QDRANT_URL=...
QDRANT_API_KEY=...
COLLECTION_NAME=bog_offers
QDRANT_DISTANCE=COSINE

Embeddings:
EMBEDDING_MODEL=BAAI/bge-m3

Retriever tuning (optional):
TOP_K=10
MIN_SIMILARITY_SCORE=0.05
LEXICAL_BOOST=0.20
MAX_RESULTS_FOR_PROMPT=6
MAX_FACTUAL_RESULTS=1
MIN_FACTUAL_OVERLAP=0.10

Follow-up / context tuning:
FOLLOWUP_OFFER_LIMIT=6
FOLLOWUP_PREV_ANSWER_MAX_CHARS=700
CONTEXT_TOPIC_KEYWORDS_LIMIT=5
CATEGORY_BROWSE_DEFAULT_N=10

LLM (optional):
LLM_PROVIDER=auto|openai|gemini|none
LLM_MODEL=auto|gpt-4o-mini|...
LLM_TEMPERATURE=0.2
OPENAI_API_KEY=...
GEMINI_API_KEY=...

================================================================================
9) SYSTEM FLOW (QUERY-TIME) — Step-by-step
================================================================================

1) მომხმარებელი წერს კითხვას UI/CLI-ში
2) chatbot იღებს query-ს
3) retriever:
   - query embedding
   - Qdrant similarity search
   - rerank_results (hybrid scoring)
4) taxonomy:
   - თითო retrieved offer-ზე normalize_offer()
   - benefit_type/value/unit მიეწერება metadata-ში
5) prompt:
   - SYSTEM_PROMPT
   - short history (optional)
   - formatted offers evidence
6) LLM call (თუ provider != none) ან retrieval-only პასუხი
7) UI აჩვენებს პასუხს და ინახავს history-ს

================================================================================
10) Troubleshooting (ხშირი პრობლემები)
================================================================================

Qdrant is not reachable
- შეამოწმე QDRANT_URL/QDRANT_API_KEY
- თუ local Qdrant-ს იყენებ, დარწმუნდი რომ გაშვებულია

LLM API key missing
- OPENAI_API_KEY ან GEMINI_API_KEY არ არის .env-ში
- LLM_PROVIDER=none შემთხვევაში ეს პრობლემა არ იქნება

Index does not return relevant results
- დარწმუნდი რომ build_index.py ერთხელ მაინც გაეშვა
- სცადე query_index.py CLI test
- გაზარდე TOP_K, ან LEXICAL_BOOST

Category filter error (Index required but not found)
- ეს ნიშნავს რომ Qdrant collection-ში payload index არ არის შექმნილი (მაგ: category_desc-ზე)
- გაუშვი: python -m rag.ensure_payload_indexes

================================================================================
11) როდის უნდა გადავაწყო ინდექსი?
================================================================================

ინდექსის rebuild რეკომენდებულია როცა:
- data/processed/found_offers.json შეიცვალა
- EMBEDDING_MODEL შეიცვალა
- Qdrant collection name შეიცვალა

როცა მხოლოდ taxonomy.json შეიცვლება:
- ამ არქიტექტურაში taxonomy query-time-ზე მუშაობს, ამიტომ rebuild სავალდებულო არაა.
  (მაგრამ თუ მომავალში taxonomy-ს payload-შიც ჩაწერ, მაშინ rebuild დაგჭირდება.)
