<h1>ვებ სქრეიფერი + RAG სისტემა + ჩათბოტი + UI</h1>

დეტალური აღწერა

<h2>I - ვებ სქრეიფერი</h2>

რამდენიმე სექციად არის დაყოფილი საიტის კომპლექსურობიდან გამომდინარე. მონაცემები მომაქვს ჯერ "დაუმუშავებლად", შემდეგ მცირე ცვლილებების გავლის მერე გადადის Processed ფოლდერში. ორივეგან ვიყენებ JSON ფორმატს.

1) <b>playwright_scrape.py</b>

გამოყენებული მაქვს package სახელად PlayWright. საწყისი იდეა იყო BS4 მაგრამ დინამიური ჩატვირთვის გამო არ იმუშავა და სელენიუმის უკეთესი ვარიანტია ეს პაკეტი.

რას აკეთებს კოდი - შედის საიტზე, ქუქიებს ადასტურებს (რადგან ინკოგნიტოში ვართ აუცილებლად დაგვჭირდება), შემდეგ ჩადის ბოლომდე ქვემოთ (lazy loading-ისგან თავის დასაზღვევად) და უცდის კონტენტის ჩატვირთვას.

ჩატვირთვის შემდეგ ეძებს გვერდების რაოდენობას (pagination) და შაბლონი არის ასეთი - გვერდის მიხედვით ლინკი გარდაიქმნება bog.ge...currentPage{<span style="color:blue;">X Page</span>}. აქედან უკვე გადადის თითოეულ გვერდზე და სქრეიფერი ირთვება.

2) <b>detail_workers.py</b>

{<span style="color:red;">კიდევ ერთი კომპლექსურობა</span>} - ძირითადი ინფო მთავარ გვერდზე იყო, აღწერა კი უშუალოდ შეთავაზების გვერდზე. ამიტომ, ჯერ ერთიანად მომქონდა მთელი დატა (მათ შორის href) და ამის შემდეგ ვუშვებ <b>4 პარალელურ worker-ს<b> და თითოეული სქრეფავს მთელ მონაცეცმებს.

Headless = False მაქვს მითითებული, ამიტომ ეს პროცესი ვიზუალურადაც კარგად ჩანს.

3) <b>city_scrape.py</b>

{<span style="color:red;">პრობლემა N3</span>} - ქალაქები არ იყო მითითებული არსად. ამისთვის აუცილებელი იყო სექციაში თითოეულის მონიშვნა და კიდევ ორი სკრაპერის გაშვება - პირველი ეძებს ქალაქებს და მათ შესაბამის კოდებს (თბილისი-37 და ა.შ). ეს აუცილებელია რადგან bog.ge...cityId=37 ასეთი ტიპის ტრანსფორმაციას ვიღებთ მოძებნისას. ამაზე ცალკე სქრაფერი იმიტომ დავამატე, რომ ქალაქის დამატების შემთხვევაში ავტმატიზირებულად შეიძლებოდეს id-ებისა და ქალაქების ბაზის განახლება. 

4) <b>append_cities.py</b>

მეორე სკრაპერი კი თითეულ ქალაქზე გადადის და ეძებს offer card-ებს, შემდეგ კი შესაბამისი თანმიმდევრობით უკეთებს append-ს დატაში.

5) <b>BONUS - taxonomy.json</b>

დავამატე მონაცემების ტაქსონომია რათა უფრო გასასგები იყოს რაგის სისტემისთვის რა რას ნიშნავს. მაგ. რას ნიშნავს "%","X" და ა.შ.







<h2>II - RAG სისტემა</h2>

ემბედინგები: BAAI/bge-m3 - Multilingual - ქართულზე კარგად მუშაობს / ზედმეტად დიდია
ვექტორ სთორი: Qdrant Cloud - ქლაუდია, არ ტვირთავს დივაისს

disclaimer-ის სახით დავამატებ რომ ასეთ დატაზე chunking საერთოდ არ არის საჭირო.

1) <b>embeddings.py</b>

    _safe_str გავაკეთე რადგან ჩემს დატაში ზოგგან ორი + მონაცემია თითო ცვლადზე (ქალაქი, ტიპი..). ქრეშებისგან გიცავს ეს რა.

    მოდელს ვუკეთებთ დეფინიციას, ემბედინგებს ნორმალიზაციას (!!!) რათა შესადარისი გახდეს Cosine Similarity-ს გამოყენებისას. მერე ვაქართულებ column-ებს - რადგან ბოტი ქართველია, ასე უფრო გასაგებია. SentenceTransformer თანხის დაზოგვაშია კარგი - არასაჭირო ტიპებს არ აქცევს ემბედინგებად.

2) <b>vector_store.py</b>

    ძირითადი ფუნქციებია - ემბედინგების შენახვა, similarity search და დაბაზის დამენეჯება.

    _ensure_serializable_payload - JSON compatibility-ს უზრუნველყოფს (ანუ ანექსფექთიდ ტიპებს აქრობს - დეითები, nested ობიექტები...). 

    წინა ფაილში წამოღბული ინფო ემბედინგების ზომის შესახებ აქ ხდება საჭირო.

    add_documents ზედაპირულად რომ ვთქვათ, იღებს კონკრეტულ id-ებს დოკუმენტებიდან, მათ ვექტორებს და მეტადატას და აერთიანებს ამ ყველაფერს. მერე similarity_search-ში query_embedding-ით ვეძებთ ტოპ 5 შეთავაზებას (რადგან top_k=5)

3) <b>retriever.py</b>

    აქ ხდება query-ის პროცესი, რელევანტური ინფოს წამოღება და მათი რანჟირება. ვავალიდირებთ რომ query არ იყოს ცარიელი, ვუკეთებთ ემბედინგს, ვეძებთ რელევანტურ ტიპებს Qdrant-ში და მერე ვაფასებთ რამდენად კარგი პასუხებია და რომელია უფრო რელევანტური. 

4) <b>taxonomy.py</b>

    ტაქსონომია როგორც ვახსენე, ვფიქრობ, ძალიან მნიშვნელოვანი იყო რადგან ბევრი აბრევიატურა და მსგავსი LLM-ისთვის "უცხო" ტერმინი გვხვდებოდა. ყველაზე ლოგიკური სთეფი როცა არქიტექტურაში უნდა იყოს ტაქსონომია გამოყენებული არის retrieving-ის პროცესში. 

5) <b>build_index.py</b>

    თითოეულ დეითა ფოინთს გადაწერს და უშვებს კვადრანტის კოლექციაში. One-Time ტიპია, გადაწერას აკეთებს, შემდეგ vectorStore-ს გამოყენებით უშვებს იქით. vector_store.py არის კვადრანტთან ურთიერთობის "გაიდლაინი", ეს არის როგორ გავუშვათ ინდექსები.

6) <b>query_index.py</b>

    smoke test არის - იაფი მეთოდია რომლითაც შეგვიძლია გავიგოთ მუშაობს თუ არა ფაიფლაინი


<h2>III - LLM</h2>

1) <b>chatbot.py</b>

    მთავარი BOGChatbot კლასი - აერთიანებს კომპონენტებს (რეტრივერი, ტაქსონომია, ლლმ). იღებს მომხმარებლის მოთხოვნას, აანალიზებს არის თუ არა Follow-up, აორკესტრირებს კონტექსტის შენახვას/გადაცემას, იძახებს რეტრივალს და ასაბმითებს LLM-ს. 

    API Call Handling (OpenAI/Gemini) - _call_llm() მეთოდი.
    
    ერორ ჰენდლინგი - API key-ების ვალიდაცია, fallback-ები.
    
    Follow-up ლოგიკა - შენახული კონტექსტის (_last_city, _last_category_desc, _last_benefit_hint, _last_assistant_response) განლაგება, carry-over decision logic, ფაქტობრივი კითხვების დეტერმინისტული პასუხები.
    
    CLI და Factory - build_default_chatbot(), main() interactive/one-shot რეჟიმებით.

2) <b>query_parser.py</b>

    მომხმარებლის query-ის ანალიზი: ქალაქის ამოცნობა (_extract_city), კატეგორიების ამოცნობა (_extract_all_categories), benefit type-ის hint-ების ამოცნობა (_extract_benefit_hint), Follow-up detection (_looks_like_follow_up), თარიღის კითხვების დეტექცია (_is_date_question), რაოდენობის პარსინგი (_parse_requested_count). 
    
    შეიცავს regex pattern-ებს და keyword mapping-ებს (_CATEGORY_KEYWORDS).

3) <b>helpers.py</b>

    დამხმარე ფუნქციები - ქალაქებისა და კატეგორიების ჩატვირთვა JSON ფაილებიდან (_load_city_labels, _load_category_labels), პასუხების ფორმატირება (_format_offer_period_answer, _format_category_list).

4) <b>prompts.py</b>

    დეტალური პრომპტ ტემფლეითები - system prompt, user message construction, offers formatting. განსაზღვრავს როგორ უნდა უპასუხოს LLM-მა მომხმარებელს.






<h2>Chatbot გაშვება (CLI)</h2>

One-shot:
- `python -m llm.chatbot "თბილისში რესტორნები ქეშბექით"`

Interactive:
- `python -m llm.chatbot`

LLM-ის გარეშე (მხოლოდ Retrieval + Taxonomy):
- `python -m llm.chatbot --no-llm "20% ფასდაკლება"`







<h2>Config / .env პარამეტრები (მნიშვნელოვანი)</h2>

<h3>Retrieval relevance tuning</h3>

- <b>MIN_SIMILARITY_SCORE</b>: დაბალი score-ის “noise” ფილტრი (თუ random შედეგებია, აწიე ~`0.15-0.25`).
- <b>LEXICAL_BOOST</b>: keyword overlap-ის ბუსტი rerank-ზე (თუ გინდა უფრო ზუსტი სახელები, აწიე ~`0.15-0.30`).
- <b>MAX_RESULTS_FOR_PROMPT</b>: რამდენ შეთავაზებას “ხედავს” LLM (თუ ურევს შეთავაზებებს, დაწიე).
- <b>MAX_FACTUAL_RESULTS</b>: ფაქტობრივ კითხვაზე (ვინ/როდის/სად/?) რამდენი შედეგი დარჩეს (რეკ: `1`).
- <b>MIN_FACTUAL_OVERLAP</b>: ფაქტობრივ კითხვაზე მინ. overlap (თუ random ფაქტებია, აწიე ~`0.10-0.20`).

<h3>LLM behavior</h3>

- <b>LLM_TEMPERATURE</b>: “კრეატიულობა” (ფაქტებზე დაფუძნებულისთვის რეკ: `0.0-0.3`).
- <b>HISTORY_TO_KEEP</b>: რამდენ ბოლო მესიჯს იტოვებს კონტექსტში (თუ წინა თემები ერევა, დაწიე).
