<h1>ვებ სქრეიფერი + RAG სისტემა + ჩათბოტი + UI</h1>

დეტალური აღწერა

<h2>I - ვებ სქრეიფერი</h2>

რამდენიმე სექციად არის დაყოფილი საიტის კომპლექსურობიდან გამომდინარე. მონაცემები მომაქვს ჯერ "დაუმუშავებლად", შემდეგ მცირე ცვლილებების გავლის მერე გადადის Processed ფოლდერში. ორივეგან ვიყენებ JSON ფორმატს.

1) <b>playwright_scrape.py</b>

გამოყენებული მაქვს package სახელად PlayWright. საწყისი იდეა იყო BS4 მაგრამ დინამიური ჩატვირთვის გამო არ იმუშავა და სელენიუმის უკეთესი ვარიანტია ეს პაკეტი.

რას აკეთებს კოდი - შედის საიტზე, ქუქიებს ადასტურებს (რადგან ინკოგნიტოში ვართ აუცილებლად დაგვჭირდება), შემდეგ ჩადის ბოლომდე ქვემოთ (lazy loading-ისგან თავის დასაზღვევად) და უცდის კონტენტის ჩატვირთვას.

ჩატვირთვის შემდეგ ეძებს გვერდების რაოდენობას (pagination) და შაბლონი არის ასეთი - გვერდის მიხედვით ლინკი გარდაიქმნება bog.ge...currentPage{<span style="color:blue;">X Page</span>}. აქედან უკვე გადადის თითოეულ გვერდზე და სქრეიფერი ირთვება.

2) <b>detail_workers.py</b>

{<span style="color:red;">კიდევ ერთი კომპლექსურობა</span>} - ძირითადი ინფო მთავარ გვერდზე იყო, აღწერა კი უშუალოდ შეთავაზების გვერდზე. ამიტომ, ჯერ ერთიანად მომქონდა მთელი დატა (მათ შორის href) და ამის შემდეგ ვუშვებ <b>4 პარალელურ worker-ს<b> და თითოეული სქრეფავს მთელ მონაცეცმებს.

Headless = False მაქვს მითითებული, ამიტომ ეს პროცესი ვიზუალურადაც კარგად ჩანს.

3) <b>city_scrape.py</b>

{<span style="color:red;">პრობლემა N3</span>} - ქალაქები არ იყო მითითებული არსად. ამისთვის აუცილებელი იყო სექციაში თითოეულის მონიშვნა და კიდევ ორი სკრაპერის გაშვება - პირველი ეძებს ქალაქებს და მათ შესაბამის კოდებს (თბილისი-37 და ა.შ). ეს აუცილებელია რადგან bog.ge...cityId=37 ასეთი ტიპის ტრანსფორმაციას ვიღებთ მოძებნისას. ამაზე ცალკე სქრაფერი იმიტომ დავამატე, რომ ქალაქის დამატების შემთხვევაში ავტმატიზირებულად შეიძლებოდეს id-ებისა და ქალაქების ბაზის განახლება. 

4) <b>append_cities.py</b>

მეორე სკრაპერი კი თითეულ ქალაქზე გადადის და ეძებს offer card-ებს, შემდეგ კი შესაბამისი თანმიმდევრობით უკეთებს append-ს დატაში.

5) <b>BONUS - taxonomy.json</b>

დავამატე მონაცემების ტაქსონომია რათა უფრო გასასგები იყოს რაგის სისტემისთვის რა რას ნიშნავს. მაგ. რას ნიშნავს "%","X" და ა.შ.







<h2>II - RAG სისტემა</h2>

ემბედინგები: BAAI/bge-m3 - Multilingual - ქართულზე კარგად მუშაობს / ზედმეტად დიდია
ვექტორ სთორი: Qdrant Cloud - ქლაუდია, არ ტვირთავს დივაისს

disclaimer-ის სახით დავამატებ რომ ასეთ დატაზე chunking საერთოდ არ არის საჭირო.

1) <b>embeddings.py</b>

    _safe_str გავაკეთე რადგან ჩემს დატაში ზოგგან ორი + მონაცემია თითო ცვლადზე (ქალაქი, ტიპი..). ქრეშებისგან გიცავს ეს რა.

    მოდელს ვუკეთებთ დეფინიციას, ემბედინგებს ნორმალიზაციას (!!!) რათა შესადარისი გახდეს Cosine Similarity-ს გამოყენებისას. მერე ვაქართულებ column-ებს - რადგან ბოტი ქართველია, ასე უფრო გასაგებია. SentenceTransformer თანხის დაზოგვაშია კარგი - არასაჭირო ტიპებს არ აქცევს ემბედინგებად.

2) <b>vector_store.py</b>

    ძირითადი ფუნქციებია - ემბედინგების შენახვა, similarity search და დაბაზის დამენეჯება.

    _ensure_serializable_payload - JSON compatibility-ს უზრუნველყოფს (ანუ ანექსფექთიდ ტიპებს აქრობს - დეითები, nested ობიექტები...). 

    წინა ფაილში წამოღბული ინფო ემბედინგების ზომის შესახებ აქ ხდება საჭირო.

    add_documents ზედაპირულად რომ ვთქვათ, იღებს კონკრეტულ id-ებს დოკუმენტებიდან, მათ ვექტორებს და მეტადატას და აერთიანებს ამ ყველაფერს. მერე similarity_search-ში query_embedding-ით ვეძებთ ტოპ 5 შეთავაზებას (რადგან top_k=5)

3) <b>retriever.py</b>

    აქ ხდება query-ის პროცესი, რელევანტური ინფოს წამოღება და მათი რანჟირება. ვავალიდირებთ რომ query არ იყოს ცარიელი, ვუკეთებთ ემბედინგს, ვეძებთ რელევანტურ ტიპებს Qdrant-ში და მერე ვაფასებთ რამდენად კარგი პასუხებია და რომელია უფრო რელევანტური. 

4) <b>taxonomy.py</b>

    ტაქსონომია როგორც ვახსენე, ვფიქრობ, ძალიან მნიშვნელოვანი იყო რადგან ბევრი აბრევიატურა და მსგავსი LLM-ისთვის "უცხო" ტერმინი გვხვდებოდა. ყველაზე ლოგიკური სთეფი როცა არქიტექტურაში უნდა იყოს ტაქსონომია გამოყენებული არის retrieving-ის პროცესში. 

5) <b>build_index.py</b>

    თითოეულ დეითა ფოინთს გადაწერს და უშვებს კვადრანტის კოლექციაში. One-Time ტიპია, გადაწერას აკეთებს, შემდეგ vectorStore-ს გამოყენებით უშვებს იქით. vector_store.py არის კვადრანტთან ურთიერთობის "გაიდლაინი", ეს არის როგორ გავუშვათ ინდექსები.

6) <b>query_index.py</b>

    smoke test არის - იაფი მეთოდია რომლითაც შეგვიძლია გავიგოთ მუშაობს თუ არა ფაიფლაინი


<h2>III - LLM</h2>

1) <b>chatbot.py</b>

    აერთიანებს კომპონენტებს და ქმნის ჩათბოთს (რეტრივერი, ტაქსონომია, ლლმ...). იღებს მომხმარებლის მოთხოვმნას და აანალიზებს ახალი რეკომენდაციაა თუ ფაქტუალური კითხვა (ძველ ან რომელიმე კონკრეტულზე ხომ არ უნდა დაზუსტება). აანალიზებს რა ისტორია უნდა შეინახოს და რა არა (Follow up). 

    API Call Handling-იც აქ ხდება. 

    ერორ ჰენდლინგის ლოგიკებიც აქ არის გაწერილი.

    Follow up-ების ლოგიკაზე დავამატე ის ნაწილიც, რომ თუ მომხმარებელი კითხულობს რაიმეს მოწოდებულ შეთავაზებებზე, ამ დრო უნდა გააქტიურდეს ჩატბოტის წინა მესიჯი (რომელიც უკვე დასეივებულია.)

2) <b>prompts.py</b>

    დეტალური პრომპტია გაწერილი, როგორ უნდა უპასუხოს მომხმარებელს და ა.შ.






<h2>Chatbot გაშვება (CLI)</h2>

One-shot:
- `python -m llm.chatbot "თბილისში რესტორნები ქეშბექით"`

Interactive:
- `python -m llm.chatbot`

LLM-ის გარეშე (მხოლოდ Retrieval + Taxonomy):
- `python -m llm.chatbot --no-llm "20% ფასდაკლება"`







<h2>Config / .env პარამეტრები (მნიშვნელოვანი)</h2>

<h3>Retrieval relevance tuning</h3>

- <b>MIN_SIMILARITY_SCORE</b>: დაბალი score-ის “noise” ფილტრი (თუ random შედეგებია, აწიე ~`0.15-0.25`).
- <b>LEXICAL_BOOST</b>: keyword overlap-ის ბუსტი rerank-ზე (თუ გინდა უფრო ზუსტი სახელები, აწიე ~`0.15-0.30`).
- <b>MAX_RESULTS_FOR_PROMPT</b>: რამდენ შეთავაზებას “ხედავს” LLM (თუ ურევს შეთავაზებებს, დაწიე).
- <b>MAX_FACTUAL_RESULTS</b>: ფაქტობრივ კითხვაზე (ვინ/როდის/სად/?) რამდენი შედეგი დარჩეს (რეკ: `1`).
- <b>MIN_FACTUAL_OVERLAP</b>: ფაქტობრივ კითხვაზე მინ. overlap (თუ random ფაქტებია, აწიე ~`0.10-0.20`).

<h3>LLM behavior</h3>

- <b>LLM_TEMPERATURE</b>: “კრეატიულობა” (ფაქტებზე დაფუძნებულისთვის რეკ: `0.0-0.3`).
- <b>HISTORY_TO_KEEP</b>: რამდენ ბოლო მესიჯს იტოვებს კონტექსტში (თუ წინა თემები ერევა, დაწიე).
